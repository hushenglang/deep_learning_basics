{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### This notebook is Convolutional neural network implementation for classifying MNIST handwritting with tensorflow.\n",
    "\n",
    "[MNIST Dataset]  http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "[Author] hushenglang@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import tensoflow lib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found. Please use a GPU to train your neural network.\n"
     ]
    }
   ],
   "source": [
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    print('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model_path = './Model/image_classification_tensorflow'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, filter_height, filter_width, out_channels, stride=1):\n",
    "    # conv layer wrapper.\n",
    "    in_channels = x.get_shape()[3].value\n",
    "    W = tf.Variable(tf.truncated_normal([filter_height, filter_width, in_channels, out_channels], seed=10))\n",
    "    b = tf.Variable(tf.truncated_normal([out_channels], seed=20))\n",
    "    conv_x = tf.nn.conv2d(x, W, strides=[1,stride,stride,1], padding=\"SAME\")\n",
    "    conv_x = tf.nn.bias_add(conv_x, b)\n",
    "    return tf.nn.relu(conv_x) # here we can also use leaky relu which can prevent dead neron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    # max pooling wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1,k,k,1], strides=[1,k,k,1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connect(x, num_hidden_units):\n",
    "    # fully connect wrapper\n",
    "    num_input = x.get_shape()[1].value;\n",
    "    W = tf.Variable(tf.truncated_normal([num_input, num_hidden_units], seed=30))\n",
    "    b = tf.Variable(tf.truncated_normal([num_hidden_units], seed=40))\n",
    "    logits = tf.matmul(x,W)+b\n",
    "    return tf.nn.relu(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(x, num_output_units):\n",
    "    # output layer wrapper\n",
    "    num_input = x.get_shape()[1].value;\n",
    "    W = tf.Variable(tf.truncated_normal([num_input, num_output_units], seed=50))\n",
    "    b = tf.Variable(tf.truncated_normal([num_output_units], seed=40))\n",
    "    logits = tf.matmul(x,W)+b\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet's architecure using here is:\n",
    "\"conv\" -> \"maxpool\" -> \"conv\" -> \"maxpool\" ->\"full connect\"+\"dropout\" -> \"outlayer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_net(x, dropout, num_hidden_units):\n",
    "    # build network graph\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1]) # Reshape input picture\n",
    "    print(x.shape)\n",
    "    \n",
    "    # conv layer 1. filter size: 5x5x32\n",
    "    conv1 = conv2d(x, 5, 5, 32, stride=1)\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    print(conv1.shape)\n",
    "\n",
    "    \n",
    "    # conv layer 2. filter size: 5x5x64\n",
    "    conv2 = conv2d(conv1, 5, 5, 64, stride=1)\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    print(conv2.shape)\n",
    "    \n",
    "    # full connect layer\n",
    "    fc1 = tf.contrib.layers.flatten(conv2); # later replace this by low-level implementation\n",
    "    fc1 = fully_connect(fc1, num_hidden_units)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout) # add dropout\n",
    "    print(fc1.shape)\n",
    "    \n",
    "    # output\n",
    "    logits = output(fc1, n_class)\n",
    "    \n",
    "    print(logits.shape)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input param\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_class = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# hyper parameter\n",
    "training_iters = 20#10*400\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "num_hidden_units = 1024\n",
    "dropout_rate = 0.8 # Dropout, probability to keep units\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 1)\n",
      "(?, 14, 14, 32)\n",
      "(?, 7, 7, 64)\n",
      "(?, 1024)\n",
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "# tf graph input\n",
    "x = tf.placeholder(tf.float32, [None, n_input], name=\"x\")\n",
    "y = tf.placeholder(tf.float32, [None, n_class], name=\"y\")\n",
    "keep_prop = tf.placeholder(tf.float32, name=\"keep_prop\")\n",
    "\n",
    "# define loss and optimizer\n",
    "logits = conv_net(x, keep_prop, num_hidden_units)\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# define evaluation accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name=\"accuracy\")\n",
    "\n",
    "# define global initializer\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training step 10/20: train_loss=16648.08203125, train_accuracy=0.4296875, validation_accuracy=0.5461999773979187\n",
      "training step 20/20: train_loss=1244.970947265625, train_accuracy=0.6953125, validation_accuracy=0.7391999959945679\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Parent directory of ./model/image_classification_tensorflow doesn't exist, can't save.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-dfa3286cb8bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Save Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/hushenglang/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsDirectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m       raise ValueError(\n\u001b[0;32m-> 1365\u001b[0;31m           \"Parent directory of {} doesn't exist, can't save.\".format(save_path))\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Parent directory of ./model/image_classification_tensorflow doesn't exist, can't save."
     ]
    }
   ],
   "source": [
    "# ready to train model\n",
    "evaluation_states = {\"train_loss\": [], \"validation_loss\": [], \"train_accuracy\": [], \"validation_accuracy\": []}\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    for i in range(training_iters):\n",
    "        train_x, train_y = mnist.train.next_batch(batch_size=batch_size)\n",
    "        sess.run(optimizer, feed_dict={x:train_x, y:train_y, keep_prop:dropout_rate})\n",
    "        \n",
    "        if step%display_step == 0: # print train_loss, validation_loss, train_accuracy, validataion_accuracy.\n",
    "            train_loss_val, train_acc_val = sess.run([loss, accuracy], feed_dict={x:train_x, y:train_y, keep_prop:1.0})\n",
    "            valid_loss_val, valid_acc_val = sess.run([loss, accuracy], feed_dict={x:mnist.validation.images, y:mnist.validation.labels, keep_prop:1.0})\n",
    "            print(\"training step {0}/{1}: train_loss={2}, train_accuracy={3}, validation_accuracy={4}\".format(step, training_iters, train_loss_val, train_acc_val, valid_acc_val))\n",
    "            evaluation_states[\"train_loss\"].append(train_loss_val)\n",
    "            evaluation_states[\"validation_loss\"].append(valid_loss_val)\n",
    "            evaluation_states[\"train_accuracy\"].append(train_acc_val)\n",
    "            evaluation_states[\"validation_accuracy\"].append(valid_acc_val)\n",
    "        step += 1\n",
    "    print (\"Optimization Finished!\")\n",
    "    \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot evaluation states\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(evaluation_states['train_loss'], label=\"train_loss\")\n",
    "plt.plot(evaluation_states['validation_loss'], label=\"validation_loss\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.plot(evaluation_states['train_accuracy'], label=\"train_accuracy\")\n",
    "plt.plot(evaluation_states['validation_accuracy'], label=\"validation_accuracy\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy mnist test images\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load model\n",
    "    loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "    loader.restore(sess, save_model_path)\n",
    "\n",
    "    # Get Tensors from loaded model\n",
    "    loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "    loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "    loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prop:0')\n",
    "    loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "\n",
    "\n",
    "print (\"Testing Accuracy:\", \\\n",
    "    sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                  y: mnist.test.labels,\n",
    "                                  keep_prop: 1.0}))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
